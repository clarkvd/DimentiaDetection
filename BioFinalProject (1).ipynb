{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sign in sheet:\n",
        "\n",
        "Sabeeh: OUT\n",
        "\n",
        "Ryan: OUT"
      ],
      "metadata": {
        "id": "DPRpSwnfs9nV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "ksvck6WUtgn8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKcQo6riLw3d"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVpnaZ-i3NEq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9trYms3Ly_f"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4_0A7Hj5WtW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.applications import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "#from keras.applications import InceptionV3\n",
        "\n",
        "%cd /content/drive/MyDrive/Bio Final Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTbjjTdzL1H5"
      },
      "source": [
        "Organize Data:\n",
        "- Append it into a dictionary where the keys are the filename and values are the label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_RtnhNB7yX8"
      },
      "outputs": [],
      "source": [
        "data = {}\n",
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      data[filename] = 'mild'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TvQDdC1AKoh"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      data[filename] = 'moderate'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUyaELADAK9O"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      data[filename] = 'non'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npH7wSTPALLQ"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      data[filename] = 'verymild'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O27eFBC2MH03"
      },
      "source": [
        "Need to use integers not strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTWIuKiFKQMw"
      },
      "outputs": [],
      "source": [
        "\n",
        "for item in data:\n",
        "  if data[item] == 'mild':\n",
        "    data[item] = 0\n",
        "  if data[item] == 'verymild':\n",
        "    data[item] = 1\n",
        "  if data[item] == 'moderate':\n",
        "    data[item] = 2\n",
        "  if data[item] == 'non':\n",
        "    data[item] = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWEICp_t3Swo"
      },
      "source": [
        "# RESNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpO2e9yQFWaw"
      },
      "outputs": [],
      "source": [
        "# RUN\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        original = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = F.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.shortcut(original)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjEi0AYtFXGu"
      },
      "outputs": [],
      "source": [
        "#RUN\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64      \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)    \n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out) \n",
        "\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "                    \n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbWwZG6SGAUR"
      },
      "outputs": [],
      "source": [
        "#DO NOT RUN, TRAINED MODEL DOES NOT NEED TO BE RUN AGAIN\n",
        "num_epochs = 5\n",
        "running_loss = 0\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if label == 0:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "        elif label == 2:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "        elif label == 1:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "        else:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([    transforms.Resize(32),    transforms.ToTensor(),    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = MyDataset(data, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ResNet18()\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "i = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/resnet.pth'\n",
        "torch.save(model.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "usTIVm9dFBNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN UNLESS YOU WANT TO EVALUATE THE MODEL\n",
        "#This code is provided in the \"Load Models\" section for later use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ResNetModel = ResNet18()\n",
        "ResNetModel = ResNetModel.to(device)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/Bio Final Project/Models/resnet.pth'\n",
        "ResNetModel.load_state_dict(torch.load(model_path))\n"
      ],
      "metadata": {
        "id": "f197CoZ84-_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dY4qhLGP2ieR"
      },
      "outputs": [],
      "source": [
        "#DO NOT RUN\n",
        "test_dataset = MyDataset(data, transform=transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "ResNetModel.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        # Move data to GPU if available\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = ResNetModel(images)\n",
        "\n",
        "        # Get predicted labels\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('Accuracy on test set: {:.2f}%'.format(100 * accuracy))\n",
        "\n",
        "# Accuracy on test set: 99.44%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDAQeNlp3XH5"
      },
      "source": [
        "# VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIARsP0t3bO0"
      },
      "outputs": [],
      "source": [
        "#DO NOT RUN, TRAINED MODEL DOES NOT NEED TO BE RUN AGAIN\n",
        "num_epochs = 5\n",
        "running_loss = 0\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if label == 0:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "        elif label == 2:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "        elif label == 1:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "        else:\n",
        "          os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = MyDataset(data, transform=preprocess)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "num_classes = 4\n",
        "model.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003, betas=(0.9, 0.999))\n",
        "\n",
        "i=0\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/vgg.pth'\n",
        "torch.save(model.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "QJVS7on-MSJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN UNLESS YOU WANT TO EVALUATE THE MODEL\n",
        "#This code is provided in the \"Load Models\" section for later use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vggmodel = models.vgg16(pretrained=False) \n",
        "num_classes = 4\n",
        "vggmodel.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "vggmodel = vggmodel.to(device)\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/vgg.pth'\n",
        "vggmodel.load_state_dict(torch.load(model_save_path))"
      ],
      "metadata": {
        "id": "zWNH0e0AMjkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAwKSgJ6aqid"
      },
      "outputs": [],
      "source": [
        "#DO NOT RUN\n",
        "test_dataset = MyDataset(data, transform=preprocess)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "vggmodel.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        outputs = vggmodel(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('Accuracy on test set: {:.2f}%'.format(100 * accuracy))\n",
        "\n",
        "# Accuracy on test set: 46.18%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGO1jLuBi90E"
      },
      "source": [
        "# Inception-V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XZ2cJKHjHjb"
      },
      "outputs": [],
      "source": [
        "#DO NOT RUN, TRAINED MODEL DOES NOT NEED TO BE RUN AGAIN\n",
        "num_epochs = 5\n",
        "running_loss = 0\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if label == 0:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "        elif label == 2:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "        elif label == 1:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "        else:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(299),   \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = MyDataset(data, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "model = models.inception_v3(pretrained=True)\n",
        "\n",
        "num_classes = 4\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, num_classes)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "\n",
        "i = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs, _ = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/inception.pth'\n",
        "torch.save(model.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "qrY4TmNlups7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN UNLESS YOU WANT TO EVALUATE THE MODEL\n",
        "#This code is provided in the \"Load Models\" section for later use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "inceptionmodel = models.inception_v3(pretrained=False)\n",
        "num_classes = 4\n",
        "inceptionmodel.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
        "\n",
        "inceptionmodel = inceptionmodel.to(device)\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/inception.pth'\n",
        "inceptionmodel.load_state_dict(torch.load(model_save_path))"
      ],
      "metadata": {
        "id": "fbt4UMHUvAI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "test_dataset = MyDataset(data, transform=transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "inceptionmodel.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        outputs = inceptionmodel(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('Accuracy on test set: {:.2f}%'.format(100 * accuracy))\n",
        "\n",
        "# Accuracy on test set: 90.48%"
      ],
      "metadata": {
        "id": "-DHzACCnvuFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AlexNet (taken from GitHub)"
      ],
      "metadata": {
        "id": "Xigl_n6etQo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "!apt-get install git -y"
      ],
      "metadata": {
        "id": "Eut6eWs8tS19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "!git clone https://github.com/wangyirui/AD_Prediction.git"
      ],
      "metadata": {
        "id": "mTQeIw1a0NID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "%cd ./AD_Prediction/"
      ],
      "metadata": {
        "id": "CVeTwkFC0T1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "from AlexNet2D import alexnet"
      ],
      "metadata": {
        "id": "RZ-kMHzx8bE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN, TRAINED MODEL DOES NOT NEED TO BE RUN AGAIN\n",
        "num_epochs = 5\n",
        "running_loss = 0\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if label == 0:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "        elif label == 2:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "        elif label == 1:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "        else:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "      \n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = MyDataset(data, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "model = alexnet(pretrained=True)\n",
        "\n",
        "num_classes = 4\n",
        "num_features = model.classifier[6].in_features\n",
        "model.classifier.fc_out = nn.Linear(1000, num_classes)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    i=0\n",
        "    for images, labels in dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "        i += 1\n"
      ],
      "metadata": {
        "id": "Xl4EZiZb7cC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/alexnet.pth'\n",
        "torch.save(model.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "TbS5KnIM8iXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN UNLESS YOU WANT TO EVALUATE THE MODEL\n",
        "#This code is provided in the \"Load Models\" section for later use\n",
        "def load_trained_model(model_path):\n",
        "    model = alexnet(pretrained=True)\n",
        "\n",
        "    num_classes = 4\n",
        "    num_features = model.classifier[6].in_features\n",
        "    model.classifier.fc_out = nn.Linear(1000, num_classes)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    return model\n",
        "\n",
        "model_load_path = '/content/drive/MyDrive/Bio Final Project/Models/alexnet.pth'\n",
        "ANmodel = load_trained_model(model_load_path)"
      ],
      "metadata": {
        "id": "ABIaGPIeSAqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "num_epochs = 5\n",
        "running_loss = 0\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if label == 0:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "        elif label == 2:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "        elif label == 1:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "        else:\n",
        "            os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "      \n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = MyDataset(data, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "a7cWB0TBZcAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MyDataset(data, transform=transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "ANmodel.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        outputs = ANmodel(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print('Accuracy on test set: {:.2f}%'.format(100 * accuracy))\n",
        "\n",
        "# Accuracy on test set: 89.51%"
      ],
      "metadata": {
        "id": "V5gq24azrfqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Models"
      ],
      "metadata": {
        "id": "ObVh41S684dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load ResNet.  Need to run the first 2 blocks of ResNet section before this\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "ResNetModel = ResNet18()\n",
        "ResNetModel = ResNetModel.to(device)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/Bio Final Project/Models/resnet.pth'\n",
        "ResNetModel.load_state_dict(torch.load(model_path))\n",
        "\n",
        "#Load VGG-16\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vggmodel = models.vgg16(pretrained=False) \n",
        "num_classes = 4\n",
        "vggmodel.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "vggmodel = vggmodel.to(device)\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/vgg.pth'\n",
        "vggmodel.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "#Load Inception-V3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "inceptionmodel = models.inception_v3(pretrained=False)\n",
        "num_classes = 4\n",
        "inceptionmodel.fc = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
        "\n",
        "inceptionmodel = inceptionmodel.to(device)\n",
        "\n",
        "model_save_path = '/content/drive/MyDrive/Bio Final Project/Models/inception.pth'\n",
        "inceptionmodel.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "#Load Alex-Net.  Need to run the first 4 sections of Alexnet section\n",
        "def load_trained_model(model_path):\n",
        "    model = alexnet(pretrained=True)\n",
        "\n",
        "    num_classes = 4\n",
        "    num_features = model.classifier[6].in_features\n",
        "    model.classifier.fc_out = nn.Linear(1000, num_classes)\n",
        "\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    return model\n",
        "\n",
        "model_load_path = '/content/drive/MyDrive/Bio Final Project/Models/alexnet.pth'\n",
        "ANmodel = load_trained_model(model_load_path)\n"
      ],
      "metadata": {
        "id": "ndH1L5rn86o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grad Cam"
      ],
      "metadata": {
        "id": "6XaXild3zZQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "class GradCamRes:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.device = device\n",
        "        self.gradient = None\n",
        "        self.activations = None\n",
        "        self.hooks = []\n",
        "        self.hooks.append(self.model.layer4[1].conv2.register_backward_hook(self.save_gradient))\n",
        "        self.hooks.append(self.model.layer4[1].conv2.register_forward_hook(self.save_activation))\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradient = grad_output[0].to(self.device)\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output.to(self.device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "    def backward_on_target(self, output, target):\n",
        "        self.model.zero_grad()\n",
        "        one_hot_output = torch.FloatTensor(1, output.size()[-1]).zero_().to(self.device)\n",
        "        one_hot_output[0][target] = 1\n",
        "        output.backward(gradient=one_hot_output, retain_graph=True)\n",
        "\n",
        "    def generate_cam(self, input_tensor, target_class=None):\n",
        "        output = self.forward(input_tensor)\n",
        "        if target_class is None:\n",
        "            target_class = output.max(1)[-1].item()\n",
        "        self.backward_on_target(output, target_class)\n",
        "        gradient = self.gradient.data.cpu().numpy()[0]\n",
        "        activations = self.activations.data.cpu().numpy()[0]\n",
        "        weights = np.mean(gradient, axis=(1, 2))\n",
        "        cam = np.sum((weights * activations.T), axis=2).T\n",
        "        cam = np.maximum(cam, 0)\n",
        "        cam = cv2.resize(cam, input_tensor.shape[2:])\n",
        "        cam = cam - np.min(cam)\n",
        "        cam = cam / np.max(cam)\n",
        "        return cam"
      ],
      "metadata": {
        "id": "VbigOhr563ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "class GradCamVGG:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.device = device\n",
        "        self.gradient = None\n",
        "        self.activations = None\n",
        "        self.hooks = []\n",
        "        self.hooks.append(self.model.features[28].register_backward_hook(self.save_gradient))\n",
        "        self.hooks.append(self.model.features[28].register_forward_hook(self.save_activation))\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradient = grad_output[0].to(self.device)\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output.to(self.device)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "    def backward_on_target(self, output, target):\n",
        "        self.model.zero_grad()\n",
        "        one_hot_output = torch.FloatTensor(1, output.size()[-1]).zero_().to(self.device)\n",
        "        one_hot_output[0][target] = 1\n",
        "        output.backward(gradient=one_hot_output, retain_graph=True)\n",
        "\n",
        "    def generate_cam(self, input_tensor, target_class=None):\n",
        "        output = self.forward(input_tensor)\n",
        "        if target_class is None:\n",
        "            target_class = output.max(1)[-1].item()\n",
        "        self.backward_on_target(output, target_class)\n",
        "        gradient = self.gradient.data.cpu().numpy()[0]\n",
        "        activations = self.activations.data.cpu().numpy()[0]\n",
        "        weights = np.mean(gradient, axis=(1, 2))  \n",
        "        cam = np.sum((weights * activations.T), axis=2).T\n",
        "        cam = np.maximum(cam, 0) \n",
        "        cam = cv2.resize(cam, input_tensor.shape[2:])  \n",
        "        cam = cam - np.min(cam) \n",
        "        cam = cam / np.max(cam)\n",
        "        return cam"
      ],
      "metadata": {
        "id": "MLzSe1S5nDVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "class GradCamInceptionV3:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model.to(device)\n",
        "        self.model.eval()\n",
        "        self.last_conv_layer = model.Mixed_7c  \n",
        "        self.gradient = None\n",
        "        self.activations = None\n",
        "        self.device = device\n",
        "\n",
        "        self.hooks = []\n",
        "        self.hooks.append(self.last_conv_layer.register_forward_hook(self.save_activation))\n",
        "        self.hooks.append(self.last_conv_layer.register_backward_hook(self.save_gradient))\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradient = grad_output[0]\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "\n",
        "    def backward_on_target(self, output, target):\n",
        "        self.model.zero_grad()\n",
        "        one_hot_output = torch.zeros(1, output.size()[-1]).to(self.device)\n",
        "        one_hot_output[0][target] = 1\n",
        "        output.backward(gradient=one_hot_output, retain_graph=True)\n",
        "\n",
        "    def generate_cam(self, input_tensor, target_class=None):\n",
        "        input_tensor = input_tensor.to(self.device)\n",
        "        output = self.forward(input_tensor)\n",
        "        if target_class is None:\n",
        "            target_class = output.max(1)[-1].item()\n",
        "        self.backward_on_target(output, target_class)\n",
        "\n",
        "        if self.gradient is None or self.activations is None:\n",
        "            raise RuntimeError(\"Gradient or activations are missing. Make sure hooks are properly registered.\")\n",
        "\n",
        "        gradients = self.gradient\n",
        "        activations = self.activations\n",
        "        weights = torch.mean(gradients, dim=(2, 3))  \n",
        "        cam = torch.sum(weights[..., None, None] * activations, dim=1)\n",
        "        cam = torch.relu(cam)\n",
        "        cam = F.interpolate(cam.unsqueeze(0), size=input_tensor.shape[2:], mode='bilinear', align_corners=False)\n",
        "        cam = cam.squeeze().detach().cpu().numpy()\n",
        "        cam = np.maximum(cam, 0) \n",
        "\n",
        "        max_value = np.max(cam)\n",
        "        if max_value != 0:\n",
        "            cam = cam / max_value  \n",
        "\n",
        "        return cam"
      ],
      "metadata": {
        "id": "7JWbNZi7xQ1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "from torchvision.models.resnet import ResNet\n",
        "\n",
        "class ANGradCam:\n",
        "    def __init__(self, model, target_layer_index):\n",
        "        self.model = model\n",
        "        self.target_layer = self.model.features[target_layer_index]\n",
        "        self.gradient = None\n",
        "        self.conv_output = None\n",
        "\n",
        "        self.target_layer.register_backward_hook(self.save_gradient)\n",
        "        self.target_layer.register_forward_hook(self.save_output)\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradient = grad_output[0]\n",
        "\n",
        "    def save_output(self, module, input, output):\n",
        "        self.conv_output = output\n",
        "\n",
        "    def forward_pass(self, input_image):\n",
        "        return self.model(input_image)\n",
        "\n",
        "    def backward_pass(self, output, class_index):\n",
        "        one_hot = torch.zeros_like(output)\n",
        "        one_hot[0][class_index] = 1\n",
        "        output.backward(gradient=one_hot, retain_graph=True)\n",
        "\n",
        "    def generate_heatmap(self, input_image, class_index):\n",
        "        self.model.zero_grad()\n",
        "\n",
        "        output = self.forward_pass(input_image)\n",
        "\n",
        "        self.backward_pass(output, class_index)\n",
        "\n",
        "        gradient = self.gradient\n",
        "\n",
        "        alpha = gradient.mean(dim=[2, 3], keepdim=True)\n",
        "\n",
        "        weighted_activations = (alpha * self.conv_output).sum(dim=1, keepdim=True)\n",
        "\n",
        "        heatmap = nn.ReLU()(weighted_activations)\n",
        "        heatmap = nn.functional.interpolate(heatmap, size=input_image.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
        "\n",
        "        return heatmap.squeeze().cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "iun60BrLzedF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "def getHeatmap(label, model, name):\n",
        "  if label == 0:\n",
        "    directory_path = '/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented'\n",
        "  if label == 1:\n",
        "    directory_path = '/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented'\n",
        "  if label == 2:\n",
        "   directory_path = '/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented'\n",
        "  if label == 3:\n",
        "    directory_path = '/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented'\n",
        "\n",
        "  \n",
        "  files = os.listdir(directory_path)\n",
        "  files = [file for file in files if os.path.isfile(os.path.join(directory_path, file))]\n",
        "  random_file = random.choice(files)\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  if name == \"Alex\":\n",
        "    grad_cam = ANGradCam(model, 10)\n",
        "    image_path = os.path.join(directory_path, random_file)\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = preprocess(image)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "    class_index = data[random_file] \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = model.to(device)\n",
        "    input_batch = input_batch.to(device)\n",
        "    heatmap = grad_cam.generate_heatmap(input_batch, class_index)\n",
        "\n",
        "  if name == \"ResNet\":\n",
        "    preprocess = transforms.Compose([    transforms.Resize(32),    transforms.ToTensor(),    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    image_path = os.path.join(directory_path, random_file)\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    grad_cam = GradCamRes(model, device)\n",
        "    heatmap = grad_cam.generate_cam(input_tensor, target_class=label)\n",
        "\n",
        "  if name == \"VGG\":\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    image_path = os.path.join(directory_path, random_file)\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    grad_cam = GradCamVGG(model, device)\n",
        "    heatmap = grad_cam.generate_cam(input_tensor, target_class=label)\n",
        "\n",
        "  if name == \"Inception\":\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    image_path = os.path.join(directory_path, random_file)\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    grad_cam = GradCamInceptionV3(model, device)\n",
        "    heatmap = grad_cam.generate_cam(input_tensor, target_class=label)\n",
        "\n",
        "  original_image = cv2.imread(image_path)\n",
        "  original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  heatmap_normalized = cv2.normalize(heatmap, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
        "\n",
        "  heatmap_resized = cv2.resize(heatmap_normalized, (original_image.shape[1], original_image.shape[0]))\n",
        "\n",
        "  heatmap_resized = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "\n",
        "  heatmap_resized_bgr = cv2.cvtColor(heatmap_resized, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "  superimposed_img = cv2.addWeighted(original_image, 0.7, heatmap_resized_bgr, 0.3, 0)\n",
        "\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(original_image)\n",
        "  plt.title('Original Image')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(superimposed_img)\n",
        "  plt.title('Image with Heatmap')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "O5BeFweYjkDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#INSTRUCTIONS:\n",
        "#FIRST SELECT A MODEL TO USE, THEN SELECT DEGREE OF DIMENTIA\n",
        "#WILL GET AN ERROR IF YOU DO NOT SELECT A MODEL FIRST\n",
        "#HEATMAPS LOOK DIFFERENT DEPENDING ON ACCURARY/TYPE OF MODEL\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def button_click_event(button):\n",
        "    label = button_to_label[button]\n",
        "    with output:\n",
        "        clear_output() \n",
        "        getHeatmap(label, model_used, model_name)\n",
        "\n",
        "model_name = None\n",
        "model_used = None\n",
        "\n",
        "def res_click():\n",
        "    global model_used, model_name\n",
        "    label = 0\n",
        "    model_name = \"ResNet\"\n",
        "    model_used = ResNetModel\n",
        "    model_name_widget.value = \"Currently Using Model: \" + model_name\n",
        "\n",
        "def vgg_click():\n",
        "    global model_used, model_name\n",
        "    label = 1\n",
        "    model_name = \"VGG\"\n",
        "    model_used = vggmodel\n",
        "    model_name_widget.value = \"Currently Using Model: \" + model_name\n",
        "\n",
        "def inception_click():\n",
        "    global model_used, model_name\n",
        "    label = 2\n",
        "    model_name = \"Inception\"\n",
        "    model_used = inceptionmodel\n",
        "    model_name_widget.value = \"Currently Using Model: \" + model_name\n",
        "\n",
        "def alex_click():\n",
        "    global model_used, model_name\n",
        "    label = 3\n",
        "    model_name = \"Alex\"\n",
        "    model_used = ANmodel\n",
        "    model_name_widget.value = \"Currently Using Model: \" + model_name\n",
        "\n",
        "# Create the buttons\n",
        "button1 = widgets.Button(description=\"Mild\")\n",
        "button2 = widgets.Button(description=\"Very Mild\")\n",
        "button3 = widgets.Button(description=\"Moderate\")\n",
        "button4 = widgets.Button(description=\"None\")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "# Create a dictionary to map buttons to labels\n",
        "button_to_label = {\n",
        "    button1: 0,\n",
        "    button2: 1,\n",
        "    button3: 2,\n",
        "    button4: 3\n",
        "}\n",
        "\n",
        "# Attach the functions to the buttons' click events\n",
        "button1.on_click(lambda _: button_click_event(button1))\n",
        "button2.on_click(lambda _: button_click_event(button2))\n",
        "button3.on_click(lambda _: button_click_event(button3))\n",
        "button4.on_click(lambda _: button_click_event(button4))\n",
        "\n",
        "modelbutton1 = widgets.Button(description=\"ResNet\")\n",
        "modelbutton2 = widgets.Button(description=\"VGG16\")\n",
        "modelbutton3 = widgets.Button(description=\"InceptionV3\")\n",
        "modelbutton4 = widgets.Button(description=\"AlexNet\")\n",
        "\n",
        "modelbutton1.on_click(lambda _: res_click())\n",
        "modelbutton2.on_click(lambda _: vgg_click())\n",
        "modelbutton3.on_click(lambda _: inception_click())\n",
        "modelbutton4.on_click(lambda _: alex_click())\n",
        "\n",
        "model_name_widget = widgets.Label(value=\"Currently Using Model: None\")\n",
        "\n",
        "# Create an HBox layout to horizontally align the buttons\n",
        "buttons_layout2 = widgets.HBox([modelbutton1, modelbutton2, modelbutton3, modelbutton4])\n",
        "buttons_layout = widgets.HBox([button1, button2, button3, button4])\n",
        "\n",
        "# Display the buttons and model name\n",
        "display(model_name_widget)\n",
        "display(buttons_layout2)\n",
        "display(buttons_layout, output)"
      ],
      "metadata": {
        "id": "_ZqmD3liiFLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fake Dimentia Image Generation"
      ],
      "metadata": {
        "id": "gQGeOXfgBuIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "manualSeed = 999\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "metadata": {
        "id": "vPYwlTLyBxaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't actually have to run anything in the next 4 sections because we save all the results to a path.  In each of them is their training loops an example of what is generated"
      ],
      "metadata": {
        "id": "BzB-dl8sHKj-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moderate"
      ],
      "metadata": {
        "id": "tIA76uwYihDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "mod = {}\n",
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      mod[filename] = 'moderate'"
      ],
      "metadata": {
        "id": "bHtqBkB2E5U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN, TRAINED MODEL DOESNT NEED TO BE RUN\n",
        "import os\n",
        "import zipfile \n",
        "import gdown\n",
        "import torch\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "ngpu = 1\n",
        "device = torch.device('cuda:0' if (\n",
        "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Moderate_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "image_size = 128\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                          std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "dataset = CelebADataset(mod, transform=transform)\n",
        "\n",
        "batch_size = 1\n",
        "num_workers = 0 if device.type == 'cuda' else 1\n",
        "pin_memory = True if device.type == 'cuda' else False\n",
        "\n",
        "celeba_dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=num_workers,\n",
        "                                                pin_memory=pin_memory,\n",
        "                                                shuffle=True)"
      ],
      "metadata": {
        "id": "Z29EDEfPEmm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 16),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n"
      ],
      "metadata": {
        "id": "165T2bbJHQDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "bUfp_JZjHR7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "batch_size = 128\n",
        "image_size = 128\n",
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 8\n",
        "lr = 0.0003\n",
        "beta1 = 0.5\n",
        "ngpu = 1\n",
        "netG = Generator(ngpu).to(device)\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "fixed_noise_mod = torch.randn(64, nz, 1, 1, device=device)\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "gqA1ZAYVHUnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT RUN, Training Loop\n",
        "\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(celeba_dataloader, 0):\n",
        "        \n",
        "        netD.zero_grad()\n",
        "        real_cpu = data.to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), 0, device=device).type(torch.float32)                \n",
        "        output = netD(real_cpu).view(-1)              \n",
        "        label.fill_(real_label)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)        \n",
        "        output = netD(fake.detach()).view(-1)              \n",
        "        label.fill_(fake_label)        \n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label) \n",
        "        output = netD(fake).view(-1)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "        \n",
        "        if i % 50 == 0:\n",
        "            dsp_str = '[%d/%d][%d/%d]' % (epoch, num_epochs, i, len(celeba_dataloader))\n",
        "            print('%s\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (dsp_str, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))       \n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise_mod).detach().cpu()\n",
        "            fake = vutils.make_grid(fake[:64], padding=2, normalize=True)\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(\"Generated fake Images\")\n",
        "            plt.imshow(np.transpose(vutils.make_grid(fake, padding=2, normalize=True),(1,2,0)))\n",
        "            plt.pause(1)\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "                    \n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "bSly8PFqHa2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "with torch.no_grad():\n",
        "    final_fake_mod = netG(fixed_noise_mod).detach().cpu()\n",
        "final_fake_grid_mod = vutils.make_grid(final_fake_mod, padding=2, normalize=True)\n"
      ],
      "metadata": {
        "id": "cpPWopakN42a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "tensor_save_path_mod = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakemoderate.pt'\n",
        "#torch.save(final_fake_grid_mod, tensor_save_path_mod)\n",
        "fakemod = torch.load(tensor_save_path_mod)"
      ],
      "metadata": {
        "id": "O_4mmS4Yn1TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Final Generated Fake Images\")\n",
        "plt.imshow(np.transpose(fakemod, (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aBFwqD5Un-h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non"
      ],
      "metadata": {
        "id": "FaTh71I_d8hP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "non = {}\n",
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      non[filename] = 'non'"
      ],
      "metadata": {
        "id": "WvfAPQ2nistv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN, MODEL ALREADY TRAINED\n",
        "import os\n",
        "import zipfile \n",
        "import gdown\n",
        "import torch\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "ngpu = 1\n",
        "device = torch.device('cuda:0' if (\n",
        "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Non_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "image_size = 64\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                          std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "dataset = CelebADataset(non, transform=transform)\n",
        "\n",
        "batch_size = 1\n",
        "num_workers = 0 if device.type == 'cuda' else 1\n",
        "\n",
        "pin_memory = True if device.type == 'cuda' else False\n",
        "\n",
        "celeba_dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=num_workers,\n",
        "                                                pin_memory=pin_memory,\n",
        "                                                shuffle=True)"
      ],
      "metadata": {
        "id": "jEQNpylmixHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n"
      ],
      "metadata": {
        "id": "pcy9n6gyeLsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "hI2-eIh7ePch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "batch_size = 128\n",
        "image_size = 64\n",
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 5\n",
        "lr = 0.0005\n",
        "beta1 = 0.5\n",
        "ngpu = 1\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise_non = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "lDS8A6pqeQHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT RUN, Training Loop\n",
        "\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(celeba_dataloader, 0):\n",
        "\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data.to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), 0, device=device).type(torch.float32)                \n",
        "        output = netD(real_cpu).view(-1)           \n",
        "        label.fill_(real_label)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake = netG(noise)        \n",
        "        output = netD(fake.detach()).view(-1)            \n",
        "        label.fill_(fake_label)        \n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  \n",
        "        output = netD(fake).view(-1)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "        \n",
        "        if i % 50 == 0:\n",
        "            dsp_str = '[%d/%d][%d/%d]' % (epoch, num_epochs, i, len(celeba_dataloader))\n",
        "            print('%s\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (dsp_str, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))       \n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise_non).detach().cpu()\n",
        "            fake = vutils.make_grid(fake[:64], padding=2, normalize=True)\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(\"Generated fake Images\")\n",
        "            plt.imshow(np.transpose(vutils.make_grid(fake, padding=2, normalize=True),(1,2,0)))\n",
        "            plt.pause(1)\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "                    \n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "fPaXMZBMeX2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "with torch.no_grad():\n",
        "    final_fake_non = netG(fixed_noise_non).detach().cpu()\n",
        "final_fake_grid_non = vutils.make_grid(final_fake_non, padding=2, normalize=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "-pAwJJEblQX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "tensor_save_path_non = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakenon.pt'\n",
        "#torch.save(final_fake_grid_non, tensor_save_path_non)\n",
        "fakenon = torch.load(tensor_save_path_non)"
      ],
      "metadata": {
        "id": "i6yZC065AiGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Final Generated Fake Images\")\n",
        "plt.imshow(np.transpose(fakenon, (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QE5o6RdTQhuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Very Mild"
      ],
      "metadata": {
        "id": "3g-WxNJbjxZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "vmild = {}\n",
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      vmild[filename] = 'vmild'"
      ],
      "metadata": {
        "id": "zr8JHrRDj0EZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN, model already trained\n",
        "import os\n",
        "import zipfile \n",
        "import gdown\n",
        "import torch\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "ngpu = 1\n",
        "device = torch.device('cuda:0' if (\n",
        "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
        "\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "image_size = 64\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                          std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "dataset = CelebADataset(vmild, transform=transform)\n",
        "\n",
        "\n",
        "batch_size = 2\n",
        "num_workers = 0 if device.type == 'cuda' else 1\n",
        "pin_memory = True if device.type == 'cuda' else False\n",
        "\n",
        "celeba_dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=num_workers,\n",
        "                                                pin_memory=pin_memory,\n",
        "                                                shuffle=True)"
      ],
      "metadata": {
        "id": "N2y_ou6tj7Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "batch_size = 128\n",
        "image_size = 64\n",
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 5\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "ngpu = 1\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise_vmild = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "2R5KgrfvkClt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN, Training Loop\n",
        "\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(celeba_dataloader, 0):\n",
        "        \n",
        "        netD.zero_grad()\n",
        "        real_cpu = data.to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), 0, device=device).type(torch.float32)                \n",
        "        output2 = netD(real_cpu).view(-1)              \n",
        "        label.fill_(real_label)\n",
        "        errD_real = criterion(output2, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output2.mean().item()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake2 = netG(noise)        \n",
        "        output2 = netD(fake2.detach()).view(-1)           \n",
        "        label.fill_(fake_label)        \n",
        "        errD_fake2 = criterion(output2, label)\n",
        "        errD_fake2.backward()\n",
        "        D_G_z1 = output2.mean().item()\n",
        "        errD = errD_real + errD_fake2\n",
        "        optimizerD.step()\n",
        "\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label) \n",
        "        output2 = netD(fake2).view(-1)\n",
        "        errG = criterion(output2, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output2.mean().item()\n",
        "        optimizerG.step()\n",
        "        \n",
        "        if i % 50 == 0:\n",
        "            dsp_str = '[%d/%d][%d/%d]' % (epoch, num_epochs, i, len(celeba_dataloader))\n",
        "            print('%s\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (dsp_str, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))       \n",
        "            with torch.no_grad():\n",
        "                fake2 = netG(fixed_noise_vmild).detach().cpu()\n",
        "            fake2 = vutils.make_grid(fake2[:64], padding=2, normalize=True)\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(\"Generated fake Images\")\n",
        "            plt.imshow(np.transpose(vutils.make_grid(fake2, padding=2, normalize=True),(1,2,0)))\n",
        "            plt.pause(1)\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "                    \n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "XPwGqkyCkK2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "with torch.no_grad():\n",
        "    final_fake_vmild = netG(fixed_noise_vmild).detach().cpu()\n",
        "final_fake_grid_vmild = vutils.make_grid(final_fake_vmild, padding=2, normalize=True)\n"
      ],
      "metadata": {
        "id": "Ubfbn3r-PRa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "tensor_save_path_vmild = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakevmild.pt'\n",
        "#torch.save(final_fake_grid_vmild, tensor_save_path_vmild)\n",
        "fakevmild = torch.load(tensor_save_path_vmild)"
      ],
      "metadata": {
        "id": "xhT53II7Pkya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Final Generated Fake Images\")\n",
        "plt.imshow(np.transpose(fakevmild, (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "70WYeOAfQKwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mild"
      ],
      "metadata": {
        "id": "tRWHQkotk8pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "mild = {}\n",
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "for i in range(2):\n",
        "  for filename in os.listdir():\n",
        "      if filename.endswith('.jpg'):\n",
        "        mild[filename] = 'mild'"
      ],
      "metadata": {
        "id": "LB-95zdBk989"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN, Model already trained\n",
        "import os\n",
        "import zipfile \n",
        "import gdown\n",
        "import torch\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "ngpu = 1\n",
        "device = torch.device('cuda:0' if (\n",
        "    torch.cuda.is_available() and ngpu > 0) else 'cpu')\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, data_dict, transform=None):\n",
        "        self.data_dict = data_dict\n",
        "        self.filenames = list(data_dict.keys())\n",
        "        self.labels = list(data_dict.values())\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Mild_Demented')\n",
        "\n",
        "        image = Image.open(filename).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "image_size = 64\n",
        "transform=transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.CenterCrop(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                          std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "dataset = CelebADataset(mild, transform=transform)\n",
        "\n",
        "\n",
        "batch_size = 1\n",
        "num_workers = 0 if device.type == 'cuda' else 1\n",
        "pin_memory = True if device.type == 'cuda' else False\n",
        "\n",
        "celeba_dataloader = torch.utils.data.DataLoader(dataset,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=num_workers,\n",
        "                                                pin_memory=pin_memory,\n",
        "                                                shuffle=True)"
      ],
      "metadata": {
        "id": "BXAchHQNlFQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "batch_size = 128\n",
        "image_size = 64\n",
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 5\n",
        "lr = 0.0005\n",
        "beta1 = 0.5\n",
        "ngpu = 1\n",
        "\n",
        "netG = Generator(ngpu).to(device)\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise_mild = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "Mkw7s-ELlMlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT RUN, Training Loop\n",
        "\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "print(\"Starting Training Loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(celeba_dataloader, 0):\n",
        "\n",
        "        netD.zero_grad()\n",
        "        real_cpu = data.to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), 0, device=device).type(torch.float32)                \n",
        "        output3 = netD(real_cpu).view(-1)           \n",
        "        label.fill_(real_label)\n",
        "        errD_real = criterion(output3, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output3.mean().item()\n",
        "\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        fake3 = netG(noise)        \n",
        "        output3 = netD(fake3.detach()).view(-1)               \n",
        "        label.fill_(fake_label)        \n",
        "        errD_fake3 = criterion(output3, label)\n",
        "        errD_fake3.backward()\n",
        "        D_G_z1 = output3.mean().item()\n",
        "        errD = errD_real + errD_fake3\n",
        "        optimizerD.step()\n",
        "\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  \n",
        "        output3 = netD(fake3).view(-1)\n",
        "        errG = criterion(output3, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output3.mean().item()\n",
        "        optimizerG.step()\n",
        "        \n",
        "        if i % 50 == 0:\n",
        "            dsp_str = '[%d/%d][%d/%d]' % (epoch, num_epochs, i, len(celeba_dataloader))\n",
        "            print('%s\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (dsp_str, errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))       \n",
        "            with torch.no_grad():\n",
        "                fake3 = netG(fixed_noise_mild).detach().cpu()\n",
        "            fake3 = vutils.make_grid(fake3[:64], padding=2, normalize=True)\n",
        "            plt.axis(\"off\")\n",
        "            plt.title(\"Generated fake Images\")\n",
        "            plt.imshow(np.transpose(vutils.make_grid(fake3, padding=2, normalize=True),(1,2,0)))\n",
        "            plt.pause(1)\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "                    \n",
        "        iters += 1"
      ],
      "metadata": {
        "id": "3x3tmzOSlPCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "with torch.no_grad():\n",
        "    final_fake_mild = netG(fixed_noise_mild).detach().cpu()\n",
        "final_fake_grid_mild = vutils.make_grid(final_fake_mild, padding=2, normalize=True)\n"
      ],
      "metadata": {
        "id": "evnDLuqfXSnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "tensor_save_path_mild = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakemild.pt'\n",
        "#torch.save(final_fake_grid_mild, tensor_save_path_mild)\n",
        "fakemild = torch.load(tensor_save_path_mild)"
      ],
      "metadata": {
        "id": "Ecjqv-ovXZNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT RUN\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Final Generated Fake Images\")\n",
        "plt.imshow(np.transpose(fakemild, (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "51zwGqzDcn8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model on Fakes"
      ],
      "metadata": {
        "id": "3YgWvXduKwp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Load the Models Trained in the 4 sections above"
      ],
      "metadata": {
        "id": "qrUwe3VhGU74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "if not os.path.exists('results'):\n",
        "    os.makedirs('results')\n",
        "\n",
        "tensor_save_path_mod = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakemoderate.pt'\n",
        "#torch.save(final_fake_grid_mod, tensor_save_path_mod)\n",
        "fakemod = torch.load(tensor_save_path_mod)\n",
        "\n",
        "tensor_save_path_non = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakenon.pt'\n",
        "#torch.save(final_fake_grid_non, tensor_save_path_non)\n",
        "fakenon = torch.load(tensor_save_path_non)\n",
        "\n",
        "tensor_save_path_vmild = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakevmild.pt'\n",
        "#torch.save(final_fake_grid_vmild, tensor_save_path_vmild)\n",
        "fakevmild = torch.load(tensor_save_path_vmild)\n",
        "\n",
        "tensor_save_path_mild = '/content/drive/MyDrive/Bio Final Project/Models/Fake Generation/fakemild.pt'\n",
        "#torch.save(final_fake_grid_mild, tensor_save_path_mild)\n",
        "fakemild = torch.load(tensor_save_path_mild)"
      ],
      "metadata": {
        "id": "TTyrJoavGeBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "top_left_mod = fakemod[0]\n",
        "top_left_mod = top_left_mod[:128,:128]\n",
        "\n",
        "top_left_mild = fakemild[0]\n",
        "top_left_mild = top_left_mild[:64,:64]\n",
        "\n",
        "top_left_vmild = fakevmild[0]\n",
        "top_left_vmild = top_left_vmild[:64,:64]\n",
        "\n",
        "top_left_non = fakenon[0]\n",
        "top_left_non = top_left_non[:64,:64]\n",
        "\n",
        "fig, axs = plt.subplots(2, 2, figsize=(8,8))\n",
        "\n",
        "axs[0, 0].imshow(top_left_mod)\n",
        "axs[0, 0].set_title('Moderate')\n",
        "\n",
        "axs[0, 1].imshow(top_left_mild)\n",
        "axs[0, 1].set_title('Mild')\n",
        "\n",
        "axs[1, 0].imshow(top_left_vmild)\n",
        "axs[1, 0].set_title('Very Mild')\n",
        "\n",
        "axs[1, 1].imshow(top_left_non)\n",
        "axs[1, 1].set_title('None')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "testdic = {top_left_mod: \"mod\", top_left_mild: \"mild\", top_left_vmild: \"vmild\", top_left_non: \"none\"}\n"
      ],
      "metadata": {
        "id": "YBhxur0oS9-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 64\n",
        "n_images_row = (fakemild.shape[2] - 2) // (image_size + 2) \n",
        "n_images_col = (fakemild.shape[1] - 2) // (image_size + 2)\n",
        "mild_image_list = []\n",
        "\n",
        "for row in range(n_images_row):\n",
        "    for col in range(n_images_col):\n",
        "        # Calculate the start and end positions of the image in the grid\n",
        "        start_x = col * (image_size + 2) + 2\n",
        "        end_x = start_x + image_size\n",
        "        start_y = row * (image_size + 2) + 2\n",
        "        end_y = start_y + image_size\n",
        "\n",
        "        # Extract the image from the grid\n",
        "        img = fakemild[:, start_y:end_y, start_x:end_x]\n",
        "        mild_image_list.append(img)\n",
        "\n",
        "image_size = 64\n",
        "n_images_row = (fakevmild.shape[2] - 2) // (image_size + 2) \n",
        "n_images_col = (fakevmild.shape[1] - 2) // (image_size + 2)\n",
        "vmild_image_list = []\n",
        "\n",
        "for row in range(n_images_row):\n",
        "    for col in range(n_images_col):\n",
        "        # Calculate the start and end positions of the image in the grid\n",
        "        start_x = col * (image_size + 2) + 2\n",
        "        end_x = start_x + image_size\n",
        "        start_y = row * (image_size + 2) + 2\n",
        "        end_y = start_y + image_size\n",
        "\n",
        "        # Extract the image from the grid\n",
        "        img = fakevmild[:, start_y:end_y, start_x:end_x]\n",
        "        vmild_image_list.append(img)\n",
        "\n",
        "image_size = 128\n",
        "n_images_row = (fakemod.shape[2] - 2) // (image_size + 2) \n",
        "n_images_col = (fakemod.shape[1] - 2) // (image_size + 2)\n",
        "mod_image_list = []\n",
        "\n",
        "for row in range(n_images_row):\n",
        "    for col in range(n_images_col):\n",
        "        # Calculate the start and end positions of the image in the grid\n",
        "        start_x = col * (image_size + 2) + 2\n",
        "        end_x = start_x + image_size\n",
        "        start_y = row * (image_size + 2) + 2\n",
        "        end_y = start_y + image_size\n",
        "\n",
        "        # Extract the image from the grid\n",
        "        img = fakemod[:, start_y:end_y, start_x:end_x]\n",
        "        mod_image_list.append(img)\n",
        "\n",
        "image_size = 64\n",
        "n_images_row = (fakenon.shape[2] - 2) // (image_size + 2) \n",
        "n_images_col = (fakenon.shape[1] - 2) // (image_size + 2)\n",
        "non_image_list = []\n",
        "\n",
        "for row in range(n_images_row):\n",
        "    for col in range(n_images_col):\n",
        "        # Calculate the start and end positions of the image in the grid\n",
        "        start_x = col * (image_size + 2) + 2\n",
        "        end_x = start_x + image_size\n",
        "        start_y = row * (image_size + 2) + 2\n",
        "        end_y = start_y + image_size\n",
        "\n",
        "        # Extract the image from the grid\n",
        "        img = fakenon[:, start_y:end_y, start_x:end_x]\n",
        "        non_image_list.append(img)\n"
      ],
      "metadata": {
        "id": "ifOgGR0hC-y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NEED TO LOAD ALEXNET FIRST BEFORE RUNNING THIS\n",
        "#INSTUCTIONS TO DO THIS ABOVE IN THE \"LOAD MODELS\" SECTION\n",
        "#\"model\" IS ALEXNET, BUT YOU CAN SWITCH IT TO A DIFFERENT ONE IF YOU WANT DIFFERENT RESULTS\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def classify_tensor(model, image_tensor, transform):\n",
        "    image_pil = to_pil_image(image_tensor)\n",
        "\n",
        "    image_rgb = image_pil.convert('RGB')\n",
        "\n",
        "    if transform is not None:\n",
        "        image_transformed = transform(image_rgb)\n",
        "\n",
        "    image_transformed = image_transformed.unsqueeze(0)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        image_transformed = image_transformed.cuda()\n",
        "\n",
        "    output = model(image_transformed)\n",
        "\n",
        "    _, predicted_label = torch.max(output, 1)\n",
        "\n",
        "    return predicted_label.item()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "#ALEXNET:\n",
        "print(\"RESULTS USING ALEXNET:\")\n",
        "mildcount = 0\n",
        "for img in mild_image_list:\n",
        "  predicted_label = classify_tensor(model, img, transform=transform)\n",
        "  if predicted_label == 0:\n",
        "    mildcount += 1\n",
        "print(\"Mild Accuracy = \", mildcount/len(mild_image_list)*100, \"%\" )\n",
        "\n",
        "vmildcount = 0\n",
        "for img in vmild_image_list:\n",
        "  predicted_label = classify_tensor(model, img, transform=transform)\n",
        "  if predicted_label == 1:\n",
        "    vmildcount += 1\n",
        "print(\"Very Mild Accuracy = \", vmildcount/len(vmild_image_list)*100, \"%\" )\n",
        "\n",
        "modcount = 0\n",
        "for img in mod_image_list:\n",
        "  predicted_label = classify_tensor(model, img, transform=transform)\n",
        "  if predicted_label == 2:\n",
        "    modcount += 1\n",
        "print(\"Moderate Accuracy = \", modcount/len(mod_image_list)*100, \"%\" )\n",
        "\n",
        "noncount = 0\n",
        "for img in non_image_list:\n",
        "  predicted_label = classify_tensor(model, img, transform=transform)\n",
        "  if predicted_label == 3:\n",
        "    noncount += 1\n",
        "print(\"Non Accuracy = \", noncount/len(non_image_list)*100, \"%\" )\n"
      ],
      "metadata": {
        "id": "NvzyEmTmuJYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StyleGan3"
      ],
      "metadata": {
        "id": "xAR3Vt2BqWK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We tried to incorporate StyleGan3 as a better method than what we have above, but it took too long and too many resources (even after buying colab+), but here is what we tried to do anyway"
      ],
      "metadata": {
        "id": "6fSijDK_-Kjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVlabs/stylegan3.git"
      ],
      "metadata": {
        "id": "srpOq_HVXtY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "os.chdir('/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented')\n",
        "data = []\n",
        "for filename in os.listdir():\n",
        "    if filename.endswith('.jpg'):\n",
        "      data.append(filename)\n",
        "\n",
        "with open('data.pkl', 'wb') as f:\n",
        "    pickle.dump(data, f)\n",
        "\n",
        "with open('data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "os.makedirs('images', exist_ok=True)\n",
        "\n",
        "for filename in data:\n",
        "    image = Image.open(filename)\n",
        "    image.save(os.path.join('images', filename))"
      ],
      "metadata": {
        "id": "33GKmOMlbNvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install ninja-build"
      ],
      "metadata": {
        "id": "eh6moHCnmk66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python '/content/drive/MyDrive/Bio Final Project/stylegan3/train.py' --outdir='/content/drive/MyDrive/Bio Final Project/stylegan3/results' --cfg=stylegan3-t --data='/content/drive/MyDrive/Bio Final Project/Dataset/Very_Mild_Demented' --gpus=1 --batch=8 --gamma=8.2 --mirror=1"
      ],
      "metadata": {
        "id": "wuvn9Wb-U_HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see above it took 50 minutes to run 0.16% of the data."
      ],
      "metadata": {
        "id": "WdwtgWbr-XRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References"
      ],
      "metadata": {
        "id": "1Y3yB4lIKzhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet: Lab 8 from class\n",
        "\n",
        "VGG16 and Inception-V3: PyTorch Keras\n",
        "\n",
        "Fine-Tuned Alexnet Model: https://github.com/wangyirui/AD_Prediction.git\n",
        "\n",
        "Grad-Cam:\n",
        "@misc{jacobgilpytorchcam,\n",
        "  title={PyTorch library for CAM methods},\n",
        "  author={Jacob Gildenblat and contributors},\n",
        "  year={2021},\n",
        "  publisher={GitHub},\n",
        "  howpublished={\\url{https://github.com/jacobgil/pytorch-grad-cam}},\n",
        "}\n",
        "\n",
        "DCGAN: Lab 10 from class\n",
        "\n",
        "StyleGan3:\n",
        "@inproceedings{Karras2021,\n",
        "  author = {Tero Karras and Miika Aittala and Samuli Laine and Erik H\\\"ark\\\"onen and Janne Hellsten and Jaakko Lehtinen and Timo Aila},\n",
        "  title = {Alias-Free Generative Adversarial Networks},\n",
        "  booktitle = {Proc. NeurIPS},\n",
        "  year = {2021}\n",
        "}"
      ],
      "metadata": {
        "id": "BIk9-hGpK33J"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hWEICp_t3Swo",
        "sGO1jLuBi90E",
        "Xigl_n6etQo1",
        "ObVh41S684dd",
        "6XaXild3zZQb",
        "gQGeOXfgBuIt",
        "tIA76uwYihDE",
        "FaTh71I_d8hP",
        "3g-WxNJbjxZ0",
        "tRWHQkotk8pm",
        "3YgWvXduKwp2",
        "xAR3Vt2BqWK4"
      ],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}